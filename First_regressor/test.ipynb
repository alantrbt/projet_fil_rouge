{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220ded0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b9274d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predt(y: np.ndarray, y_predt: np.ndarray, name: str) -> None:\n",
    "    s = 25\n",
    "    plt.scatter(y[:, 0], y[:, 1], c=\"navy\", s=s, edgecolor=\"black\", label=\"data\")\n",
    "    plt.scatter(\n",
    "        y_predt[:, 0], y_predt[:, 1], c=\"cornflowerblue\", s=s, edgecolor=\"black\"\n",
    "    )\n",
    "    plt.xlim([-1, 2])\n",
    "    plt.ylim([-1, 2])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def gen_circle() -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"Generate a sample dataset that y is a 2 dim circle.\"\n",
    "    rng = np.random.RandomState(1994)\n",
    "    X = np.sort(200 * rng.rand(100, 1) - 100, axis=0)\n",
    "    y = np.array([np.pi * np.sin(X).ravel(), np.pi * np.cos(X).ravel()]).T\n",
    "    y[::5, :] += 0.5 - rng.rand(20, 2)\n",
    "    y = y - y.min()\n",
    "    y = y / y.max()\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def rmse_model(plot_result: bool, strategy: str) -> None:\n",
    "    \"\"\"Draw a circle with 2-dim coordinate as target variables.\"\"\"\n",
    "    X, y = gen_circle()\n",
    "    # Train a regressor on it\n",
    "    reg = xgb.XGBRegressor(\n",
    "        tree_method=\"hist\",\n",
    "        n_estimators=128,\n",
    "        n_jobs=16,\n",
    "        max_depth=8,\n",
    "        multi_strategy=strategy,\n",
    "        subsample=0.6,\n",
    "    )\n",
    "    reg.fit(X, y, eval_set=[(X, y)])\n",
    "\n",
    "    y_predt = reg.predict(X)\n",
    "    if plot_result:\n",
    "        plot_predt(y, y_predt, \"multi\")\n",
    "\n",
    "\n",
    "def custom_rmse_model(plot_result: bool, strategy: str) -> None:\n",
    "    \"\"\"Train using Python implementation of Squared Error.\"\"\"\n",
    "\n",
    "    def gradient(predt: np.ndarray, dtrain: xgb.DMatrix) -> np.ndarray:\n",
    "        \"\"\"Compute the gradient squared error.\"\"\"\n",
    "        y = dtrain.get_label().reshape(predt.shape)\n",
    "        return predt - y\n",
    "\n",
    "    def hessian(predt: np.ndarray, dtrain: xgb.DMatrix) -> np.ndarray:\n",
    "        \"\"\"Compute the hessian for squared error.\"\"\"\n",
    "        return np.ones(predt.shape)\n",
    "\n",
    "    def squared_log(\n",
    "        predt: np.ndarray, dtrain: xgb.DMatrix\n",
    "    ) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        grad = gradient(predt, dtrain)\n",
    "        hess = hessian(predt, dtrain)\n",
    "        # both numpy.ndarray and cupy.ndarray works.\n",
    "        return grad, hess\n",
    "\n",
    "    def rmse(predt: np.ndarray, dtrain: xgb.DMatrix) -> Tuple[str, float]:\n",
    "        y = dtrain.get_label().reshape(predt.shape)\n",
    "        v = np.sqrt(np.mean(np.power(y - predt, 2)))\n",
    "        return \"PyRMSE\", v\n",
    "\n",
    "    X, y = gen_circle()\n",
    "    Xy = xgb.DMatrix(X, y)\n",
    "    results: Dict[str, Dict[str, List[float]]] = {}\n",
    "    # Make sure the `num_target` is passed to XGBoost when custom objective is used.\n",
    "    # When builtin objective is used, XGBoost can figure out the number of targets\n",
    "    # automatically.\n",
    "    booster = xgb.train(\n",
    "        {\n",
    "            \"tree_method\": \"hist\",\n",
    "            \"num_target\": y.shape[1],\n",
    "            \"multi_strategy\": strategy,\n",
    "        },\n",
    "        dtrain=Xy,\n",
    "        num_boost_round=128,\n",
    "        obj=squared_log,\n",
    "        evals=[(Xy, \"Train\")],\n",
    "        evals_result=results,\n",
    "        custom_metric=rmse,\n",
    "    )\n",
    "\n",
    "    y_predt = booster.inplace_predict(X)\n",
    "    if plot_result:\n",
    "        plot_predt(y, y_predt, \"multi\")\n",
    "\n",
    "    np.testing.assert_allclose(\n",
    "        results[\"Train\"][\"rmse\"], results[\"Train\"][\"PyRMSE\"], rtol=1e-2\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6f37e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--plot\", choices=[0, 1], type=int, default=1)\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # Train with builtin RMSE objective\n",
    "    # - One model per output.\n",
    "    rmse_model(args.plot == 1, \"one_output_per_tree\")\n",
    "    # - One model for all outputs, this is still working in progress, many features are\n",
    "    # missing.\n",
    "    rmse_model(args.plot == 1, \"multi_output_tree\")\n",
    "\n",
    "    # Train with custom objective.\n",
    "    # - One model per output.\n",
    "    custom_rmse_model(args.plot == 1, \"one_output_per_tree\")\n",
    "    # - One model for all outputs, this is still working in progress, many features are\n",
    "    # missing.\n",
    "    custom_rmse_model(args.plot == 1, \"multi_output_tree\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
